import uuid
import hashlib
import boto3
mapping = {}
names = {}
uuids = {}
chksums = {}
buckets = {}
mapped = 'mapped/mapping.txt'

def get_md5(file, block_size=2**20):
# http://stackoverflow.com/questions/1131220/get-md5-hash-of-big-files-in-python
    md5 = hashlib.md5() # must get a new instance!!!!!
    with open(file,'rb') as f:
        for chunk in iter(lambda: f.read(block_size), b''):
             md5.update(chunk)
    return md5.hexdigest()

def get_mapped():
    global names
    global mapping
    global uuids

    if os.path.exists(mapped):
        fmap = open(mapped, "r")
        for line in fmap.readlines():
            line = line.rstrip().lstrip()
            (uid, name, chksum, bucket) = line.split()

            name = re.sub('\.fastq.gz$', '', name)
            uid = re.sub('\.fastq.gz$', '', uid)
            names[name] = uid
            chksums[name] = chksum
            buckets[name] = bucket
            root = re.sub('_R[12].*$', '', name)
            uid = re.sub('_R[12]$', '', uid)
            mapping[root] = uid
            uuids[uid] = root
        fmap.close()

def get_fastq_files():
    fastqs = []
    
    if os.path.exists("files.txt"):
        fin = open("files.txt", "r")
        for line in fin.readlines():
            if re.search('^\s*#', line):  # comment lines
                continue
            if re.search('^\s*$', line):  # blank lines
                continue
            name = re.sub('#.*$', '', line).rstrip().lstrip() # also remove comments
            fastqs.append(name)
        fin.close()
    #else:
        #print("files.txt doesn't exist!")

    return(fastqs)

def get_uuid(name):
    global mapping
    global uuids
    # name = re.sub('.*/', '', name)
    # name = name.rstrip('.gz')    # make sure files are gziped
    # root = re.sub('_R[12].*\.fastq\.gz$', '', name)
    root = re.sub('_R[12].*$', '', name)
    tail = re.sub(root, '', name)
    tail = re.sub('^(...).*', r'\1', tail)

    if root in mapping:
        uid = mapping[root]
    else:
        uid = str(uuid.uuid4())
        while uid in uuids:       # make sure no collision
            uid = str(uuid.uuid4())
        mapping[root] = uid
        uuids[uid] = root

    return uid + tail

def get_uuids():
    global uuids
    global names
    global mapping

    has_new = False

    get_mapped()

    for line in get_fastq_files():
        # <bucket>:<s3_path>/<sample_file_name>
        name = re.sub('.*/', '', line)
        name = re.sub('\.fastq.gz$', '', name)
        if not name in names:
            has_new = True
            # print(name)
            bucket = re.sub('[^/]+$', '', line)
            uid = get_uuid(name)   # uid includes _R1 or _R2
            buckets[name] = bucket
            names[name] = uid
            chksums[name] = get_md5('fastq/' + name + '.fastq.gz')
     
    if has_new:
        keys = sorted(list(names.keys()))
        with open(mapped, "w") as fmap:
            for name in keys:
               # print(name)
               fmap.write(names[name] + ".fastq.gz " + name + ".fastq.gz " + chksums[name] + " " + buckets[name] + "\n")

    return [name + '.fastq.gz' for name in names]

def upload_mapfile():
    tgt = "test/mapping.txt"
    cmd = "aws --profile risaws s3api put-object --bucket chop-grin --request-payer requester --server-side-encryption AES256 --key %s --body %s" % (tgt, mapped)
    # print(cmd)
    # shell(cmd)

def lookup_uuid(name):
    return names[name]

rule mapping:
    input: fastq = "fastq/{name}.fastq.gz", filelist="files.txt"
    output: fastq = "mapped/{name}.fastq.gz"
    run:
        tgt = names[wildcards.name] + '.fastq.gz'

        if not os.path.exists(tgt):
            cmd = "ln -s ../%s mapped/%s" % (input.fastq, tgt)
            # print(cmd)
            shell(cmd)

        cmd = "ln -s %s mapped/%s.fastq.gz" % (tgt, wildcards.name)
        # print(cmd)
        shell(cmd)

rule uploading:
    input: fastq = "mapped/{name}.fastq.gz"
    output: fastq = "uploaded/{name}.fastq.gz"
    run:
        (bucket, path) = buckets[wildcards.name].split(':')
        name = names[wildcards.name] + '.fastq.gz'
        tgt = path + name    # path should have a trailing slash (/)
        src = 'fastq/' + wildcards.name + '.fastq.gz'

        # print('copy ' + src + ' to ' + tgt + ' ...')
        #cmd = "aws --profile risaws s3api put-object --bucket %s --request-payer requester --server-side-encryption AES256 --key %s --body %s" % (bucket, tgt, src)
        # print(cmd)
        # shell(cmd)

        # requires a default entry in ~/.aws/credentials
        s3 = boto3.client('s3')
        data = open(src, "rb")
        res = s3.put_object(Bucket=bucket,
                            Body=data,
                            Key=path+name,
                            ServerSideEncryption='AES256')

        cmd = "ln -s ../mapped/%s %s" % (name, output.fastq)
        # print(cmd)
        shell(cmd)

rule metadata:
    input: pair1="mapped/{name}_R1.fastq.gz", pair2="mapped/{name}_R2.fastq.gz"
    output: lookup_uuid("{name}")
    run:
        with open("meta/" + wildcards.name+ ".meta", "w") as fout:
            fout.write('''
{
  "submission_type": "sequence", 
  "submission_status": "active",
  "submitter_id": "CCMCH",
  "data_type": "fastq",
  "sample": "5eb427c5-5668-472e-9bb1-a1268b4425a2",
  "reads": [{
    "path": "http://wuxi-demo-trios.s3.amazonaws.com/8949bd8f-8b3c-4615-b55c-61ad489367de_1.fq.gz", 
    "md5sum": "b9ba8a9c31907e09c2cc02eb3b02c82b", 
    "internal_id": "E01175-L2_S13_L003_R1_001.fastq",
    "flowcell": "123FUAAXX",
    "lane": 1,
    "paired_end": 1
    },{
    "path": "http://wuxi-demo-trios.s3.amazonaws.com/8949bd8f-8b3c-4615-b55c-61ad489367de_2.fq.gz", 
    "md5sum": "0b553a2255d43a80a79375ea63e1e18a", 
    "internal_id": "E01175-L2_S13_L003_R2_001.fastq",
    "flowcell": "123FUAAXX",
    "lane": 1,
    "paired_end": 2
  }],
  "platform": "Illumina HiSeq 4000",
  "capture": "Agilent SureSelect Human All Exon 50mb",
  "technique": "WES",
  "comments": "second run"
}
''')

